{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tVff4dgKyg"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xB4G8ogKym"
      },
      "source": [
        "### Carregando Arquivo de Treinamento (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5MRh5ZfgKyn",
        "outputId": "96635360-a74e-40d4-d1ce-19eaa4fefcc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Dados dos Pacientes - TREINAMENTO - Dimensão  (768, 9)\n",
            "--------------------------------------------------------\n",
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[148.     72.     35.      0.     33.6     0.627]\n",
            " [ 85.     66.     29.      0.     26.6     0.351]\n",
            " [183.     64.      0.      0.     23.3     0.672]\n",
            " ...\n",
            " [121.     72.     23.    112.     26.2     0.245]\n",
            " [126.     60.      0.      0.     30.1     0.349]\n",
            " [ 93.     70.     31.      0.     30.4     0.315]]\n",
            "----------------------------\n",
            "Classificação Supervisionada\n",
            "----------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/EduardoSSBispo/IA--Atividade-08--Redes--Neurais/main/diabetesAprendizado.csv'\n",
        "base_Treinamento = pd.read_csv(url,sep=';', encoding = 'latin1').values\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"Dados dos Pacientes - TREINAMENTO - Dimensão \",base_Treinamento.shape)\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(base_Treinamento)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento[:, 1:7])\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"Classificação Supervisionada\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Treinamento[:, 8])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpDXy7cgKyp"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "L4nvyQJegKyq",
        "outputId": "f9e5cf1f-b0c8-457c-d9eb-65e3265881e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:612: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:612: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:612: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/arraysetops.py:612: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-df519aaa6eb4>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Atributos categóricos com valores saudável e doente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'saudável'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doente'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_Treinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#Concatenação de Atributos (Colunas)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The object was not fitted with multilabel input.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         return label_binarize(\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;34m\"%s target data is not supported with label binarization\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: continuous target data is not supported with label binarization"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "\n",
        "febre = lb.transform(base_Treinamento[:,1])\n",
        "enjoo = lb.transform(base_Treinamento[:,2])\n",
        "dores = lb.transform(base_Treinamento[:,4])\n",
        "manchas = lb.transform(base_Treinamento[:,3])\n",
        "\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "lb.fit(['saudável', 'doente'])\n",
        "classes = lb.transform(base_Treinamento[:,8])\n",
        "\n",
        "#Concatenação de Atributos (Colunas)\n",
        "atributos_norm = np.column_stack((febre,enjoo,manchas,dores))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Classificação Supervisionada - Numéricos\")\n",
        "print(\"----------------------------------------\")\n",
        "diagnostico_norm = np.hstack((classes))\n",
        "print(diagnostico_norm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4FUfD5gKyr"
      },
      "source": [
        "### Treinamento do KNN (K-Nearest Neighbor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDmPLB5FgKys"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Treinamento do Knn a partir dos atributos de entrada e classificações com K=3\n",
        "modelo = KNeighborsClassifier(n_neighbors=1)\n",
        "modelo.fit(atributos_norm, diagnostico_norm)\n",
        "\n",
        "# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)\n",
        "# Acurácia do modelo: indica uma performance geral do modelo.\n",
        "# Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "# (VP+VN)/N\n",
        "print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwrAoNwgKyt"
      },
      "source": [
        "### ----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKPw4jagKyu"
      },
      "source": [
        "# Validação do Aprendizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUmMoPHgKyv"
      },
      "source": [
        "### Predição Simples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4MRpx9PgKyw"
      },
      "outputs": [],
      "source": [
        "Luiz = [[0,0,1,1]]\n",
        "print(\"Luiz\", modelo.predict(Luiz))\n",
        "Laura = [[1,1,0,1]]\n",
        "print(\"Laura\", modelo.predict(Laura))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VweXD-8_gKyx"
      },
      "source": [
        "### Predição a partir de base de dados (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceg0-DfVgKyx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/EduardoSSBispo/IA--Atividade-08--Redes--Neurais/main/diabetesTeste.csv'\n",
        "base_Testes = pd.read_csv(url,sep=';', encoding = 'latin1').values\n",
        "print(\"----------------------------\")\n",
        "print(\"Dados dos Pacientes - TESTES\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Testes)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Testes[:, 1:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6JQnLaEgKyx"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJM8C3IDgKyy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "lb.fit(['sim', 'não'])\n",
        "febre = lb.transform(base_Testes[:,1])\n",
        "enjoo = lb.transform(base_Testes[:,2])\n",
        "dores = lb.transform(base_Testes[:,4])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "lb.fit(['grandes', 'pequenas'])\n",
        "manchas = lb.transform(base_Testes[:,3])\n",
        "\n",
        "#Concatenação de Atributos (Colunas)\n",
        "atributos_norm = np.column_stack((febre,enjoo,manchas,dores))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO3B6S3gKyy"
      },
      "source": [
        "### Predição da Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZovGGdmgKyz"
      },
      "outputs": [],
      "source": [
        "base_Predicao = modelo.predict((atributos_norm))\n",
        "print(\"Classificações: \", base_Predicao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ZxJwGAgKyz"
      },
      "source": [
        "### Retorno aos valores Categóricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE96lEuPgKy0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "lb.fit(['sim', 'não'])\n",
        "febre = lb.inverse_transform(atributos_norm[:,0])\n",
        "enjoo = lb.inverse_transform(atributos_norm[:,1])\n",
        "dores = lb.inverse_transform(atributos_norm[:,3])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "lb.fit(['grandes', 'pequenas'])\n",
        "manchas = lb.inverse_transform(atributos_norm[:,2])\n",
        "\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "lb.fit(['saudável', 'doente'])\n",
        "predicao = lb.inverse_transform(base_Predicao)\n",
        "\n",
        "#Concatenação de Atributos (Colunas)\n",
        "atributos_cat = np.column_stack((base_Testes[:,0],febre,enjoo,manchas,dores,predicao))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_cat)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}